{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitminerlcondae7ee8613965e485db01fcb07abc3d477",
   "display_name": "Python 3.8.5 64-bit ('minerl': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import struct\n",
    "import socket\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import gym\n",
    "import minerl\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dqnagent import DQNAgent\n",
    "\n",
    "import faulthandler; faulthandler.enable()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG) # set to INFO if you want fewer messages\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:minerl.env.malmo.instance.9b298d:Starting Minecraft process: ['/tmp/tmp7rm6fg7s/Minecraft/launchClient.sh', '-port', '11650', '-env', '-runDir', '/tmp/tmp7rm6fg7s/Minecraft/run']\n",
      "INFO:minerl.env.malmo.instance.9b298d:Starting process watcher for process 14361 @ localhost:11650\n",
      "INFO:minerl.env.malmo.instance.9b298d:Minecraft process ready\n",
      "INFO:minerl.env.malmo:Logging output of Minecraft to ./logs/mc_2650.log\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MineRLNavigateDense-v0')\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_keys = list(env.action_space.sample().keys())\n",
    "act_keys = ['attack','back','forward','jump','left','place','right','sneak','sprint','camera']\n",
    "n_actions = len(act_keys) + 2 #act_keys + camera(the other direction) + no-op\n",
    "\n",
    "video_height = 64\n",
    "video_width = 64\n",
    "    \n",
    "def im_prep(data):\n",
    "    # data = torch.tensor(data)\n",
    "    # data = data.view(video_height,video_width,-1)\n",
    "    marg = 255/2.0\n",
    "    data = (data - marg)/marg\n",
    "    return data.permute(2,0,1).unsqueeze(0)\n",
    "\n",
    "def format_action(no_act,act_ind): \n",
    "    if act_ind > 10:\n",
    "        act_ind = 10\n",
    "    elif act_ind < 0:\n",
    "        act_ind = 0\n",
    "\n",
    "    action = no_act()\n",
    "\n",
    "    if act_ind < 9:\n",
    "        action[act_keys[act_ind]] = 1\n",
    "    elif act_ind == 9 or act_ind == 10:\n",
    "        action[act_keys[-1]] = 90*pow(-1,act_ind%9)\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'permute'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba7d4b82417a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7e15d43cefc1>\u001b[0m in \u001b[0;36mim_prep\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformat_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_act\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "num_reps = 3\n",
    "\n",
    "dqn_agent = DQNAgent(video_height,video_width,n_actions,device)\n",
    "\n",
    "for i_episode in range(num_reps):\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        state = im_prep(obs['pov'])\n",
    "\n",
    "        # Select and perform an action\n",
    "        action = dqn_agent.act(state)\n",
    "        action_command = format_action(action.squeeze())\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # Observe new state\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        next_state = im_prep(next_obs['pov'])\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        dqn_agent.memory.push(state, action, next_state, reward)\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        # state = copy.deepcopy(next_state)\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        dqn_agent.optimize()\n",
    "\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % dqn_agent.TARGET_UPDATE == 0:\n",
    "        dqn_agent.target_update()\n",
    "\n",
    "    logger.info(\"Episode has ended.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}